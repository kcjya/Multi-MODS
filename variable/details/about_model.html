<article class="Post-Main Post-NormalMain" tabindex="-1"><header class="Post-Header"><h1 class="Post-Title">Pytorch格式 .pt .pth .bin .onnx 详解</h1><div class="Post-Author"><div class="AuthorInfo" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><div class="AuthorInfo"><meta itemprop="name" content="薛定谔的问题"><meta itemprop="image" content="https://picx.zhimg.com/v2-ddd1ebf200cf6f986a41c30925f5e610_l.jpg?source=172ae18b"><meta itemprop="url" content="https://www.zhihu.com/people/xue-ding-e-de-wen-ti"><meta itemprop="zhihu:followerCount"><span class="UserLink AuthorInfo-avatarWrapper"><div class="css-1gomreu"><a href="//www.zhihu.com/people/xue-ding-e-de-wen-ti" target="_blank" class="UserLink-link" data-za-detail-view-element_name="User"><img class="Avatar AuthorInfo-avatar css-1y9jkzv" src="https://picx.zhimg.com/v2-ddd1ebf200cf6f986a41c30925f5e610_l.jpg?source=172ae18b" srcset="https://picx.zhimg.com/v2-ddd1ebf200cf6f986a41c30925f5e610_l.jpg?source=172ae18b 2x" alt="薛定谔的问题"></a></div></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name"><div class="css-1gomreu"><a href="//www.zhihu.com/people/xue-ding-e-de-wen-ti" target="_blank" class="UserLink-link" data-za-detail-view-element_name="User">薛定谔的问题</a></div><span rel="noopener noreferrer" class="css-2dtzk2">&ZeroWidthSpace;<img src="https://pica.zhimg.com/v2-4812630bc27d642f7cafcd6cdeca3d7a.jpg?source=88ceefae" alt="" class="css-1m3x3v9"></span></span></div><div class="AuthorInfo-detail"><div class="AuthorInfo-badge"><div class="ztext AuthorInfo-badgeText css-0">薛定谔的问题，不问不知道</div></div></div></div></div></div><button type="button" class="Button FollowButton Button--primary Button--blue"><span style="display:inline-flex;align-items:center">&ZeroWidthSpace;<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Plus FollowButton-icon" fill="currentColor"><path fill-rule="evenodd" d="M13.25 3.25a1.25 1.25 0 1 0-2.5 0v7.5h-7.5a1.25 1.25 0 1 0 0 2.5h7.5v7.5a1.25 1.25 0 1 0 2.5 0v-7.5h7.5a1.25 1.25 0 0 0 0-2.5h-7.5v-7.5Z" clip-rule="evenodd"></path></svg></span>关注</button></div><div class="LabelContainer-wrapper"></div><div role="button" tabindex="0"><span class="Voters"><button type="button" class="Button Button--plain">137 人<!-- -->赞同了该文章</button></span></div></header><div class="Post-RichTextContainer"><div class="css-1yuhvjn"><div class="css-376mun"><div class="css-gqz3x7"><div class="css-1sbxfcm"><div class="css-s1xz2x"><div><div class="Catalog isCatalogV2 css-17v5fjs" data-za-detail-view-name="正文"><div class="css-8kjoqe"><div class="css-wgpue5"><div class="css-zkfaav"><span style="display: inline-flex; align-items: center;">&ZeroWidthSpace;<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="ZDI ZDI--Catalog24" fill="currentColor"><path d="M10 5a1 1 0 011-1h10a1 1 0 110 2H11a1 1 0 01-1-1zm4 6a1 1 0 100 2h7a1 1 0 100-2h-7zm0 7a1 1 0 100 2h7a1 1 0 100-2h-7zm-8.335.25a.915.915 0 01-.915-.915V12.75H10a.75.75 0 000-1.5H4.75V6.665c0-.505.41-.915.915-.915H7a.75.75 0 000-1.5H5.665A2.415 2.415 0 003.25 6.665v10.67a2.415 2.415 0 002.415 2.415H10a.75.75 0 000-1.5H5.665z"></path></svg></span><div class="css-5287jj">目录</div></div><div class="css-17oyyq4">收起</div></div></div><div class="css-vm33ny"><div class="Catalog-content css-a3sv8e"><div class="Catalog-FirstLevelTitle Catalog-Title css-1kilzsx"><div data-catalog-target-id="h_620688513_0" data-za-detail-view-id="9745" data-za-detail-view-action="Click" data-za-detail-view-name="正文" class="css-hvuawc"><div class="css-nj7ofv">模型的保存与加载到底在做什么？</div></div></div><div class="Catalog-FirstLevelTitle Catalog-Title css-1kilzsx"><div data-catalog-target-id="h_620688513_1" data-za-detail-view-id="9745" data-za-detail-view-action="Click" data-za-detail-view-name="正文" class="css-hvuawc"><div class="css-nj7ofv">为什么要约定格式？</div></div></div><div class="Catalog-FirstLevelTitle Catalog-Title css-1j4gbp4"><div data-catalog-target-id="h_620688513_2" data-za-detail-view-id="9745" data-za-detail-view-action="Click" data-za-detail-view-name="正文" class="css-hvuawc"><div class="css-nj7ofv">格式汇总</div></div></div><div class="Catalog-FirstLevelTitle Catalog-Title css-1kilzsx"><div data-catalog-target-id="h_620688513_3" data-za-detail-view-id="9745" data-za-detail-view-action="Click" data-za-detail-view-name="正文" class="css-hvuawc"><div class="css-nj7ofv">.pt .pth格式</div></div></div><div class="Catalog-FirstLevelTitle Catalog-Title css-1kilzsx"><div data-catalog-target-id="h_620688513_4" data-za-detail-view-id="9745" data-za-detail-view-action="Click" data-za-detail-view-name="正文" class="css-hvuawc"><div class="css-nj7ofv">.bin格式</div></div></div><div class="Catalog-FirstLevelTitle Catalog-Title css-1kilzsx"><div data-catalog-target-id="h_620688513_5" data-za-detail-view-id="9745" data-za-detail-view-action="Click" data-za-detail-view-name="正文" class="css-hvuawc"><div class="css-nj7ofv">.onnx格式</div></div></div><div class="Catalog-FirstLevelTitle Catalog-Title css-1kilzsx"><div data-catalog-target-id="h_620688513_6" data-za-detail-view-id="9745" data-za-detail-view-action="Click" data-za-detail-view-name="正文" class="css-hvuawc"><div class="css-nj7ofv">直接保存完整模型</div></div></div><div class="Catalog-FirstLevelTitle Catalog-Title css-1kilzsx"><div data-catalog-target-id="h_620688513_7" data-za-detail-view-id="9745" data-za-detail-view-action="Click" data-za-detail-view-name="正文" class="css-hvuawc"><div class="css-nj7ofv">结语</div></div></div><div class="Catalog-FirstLevelTitle Catalog-Title css-1kilzsx"><div data-catalog-target-id="h_620688513_8" data-za-detail-view-id="9745" data-za-detail-view-action="Click" data-za-detail-view-name="正文" class="css-hvuawc"><div class="css-nj7ofv">参考资料</div></div></div></div></div></div></div></div></div></div><div class="RichText ztext Post-RichText css-1g0fqss" options="[object Object]"><p data-first-child="" data-pid="sHqgdumd"><b>非常感谢评论区知友的指正，现在已经更新了文章，更新时间：2023/04/14</b></p><p data-pid="rELNN1zd">---------------------分割线-----------------------</p><p data-pid="jsPLLlzX">Pytorch是深度学习领域中非常流行的框架之一，支持的模型保存格式包括.pt和.pth .bin .onnx。这几种格式的文件都可以保存Pytorch训练出的模型，但是它们的区别是什么呢？</p><h2 id="h_620688513_0" data-into-catalog-status="">模型的保存与加载到底在做什么？</h2><p data-pid="Ouo9xys-">我们在使用pytorch构建模型并且训练完成后，下一步要做的就是把这个模型放到实际场景中应用，或者是分享给其他人学习、研究、使用。因此，我们开始思考一个问题，提供哪些模型信息，能够让对方能够完全复现我们的模型？</p><ul><li data-pid="0NhNukQw"><b>模型代码</b>：</li><ul><li data-pid="1jP4fC_H">（1）包含了我们如何定义模型的结构，包括模型有多少层/每层有多少神经元等等信息；</li><li data-pid="tuxg4lYg">（2）包含了我们如何定义的训练过程，包括epoch batch_size等参数；</li><li data-pid="xLzI8O7K">（3）包含了我们如何加载数据和使用；</li><li data-pid="shcYBZPf">（4）包含了我们如何测试评估模型。</li></ul><li data-pid="ZjDNMQAF"><b>模型参数</b>：提供了模型代码之后，对方确实能够复现模型，但是运行的参数需要重新训练才能得到，而没有办法在我们的模型参数基础上继续训练，因此对方还希望我们能够把模型的参数也保存下来给对方。</li><ul><li data-pid="r7effVHk">（1）包含model.state_dict()，这是模型每一层可学习的节点的参数，比如weight/bias；</li><li data-pid="QTgA1fCO">（2）包含optimizer.state_dict()，这是模型的优化器中的参数；</li><li data-pid="QEmk1T9Y">（3）包含我们其他参数信息，如epoch/batch_size/loss等。</li></ul><li data-pid="unlMWaG6"><b>数据集</b>：</li><ul><li data-pid="agqB6ZQb">（1）包含了我们训练模型使用的所有数据；</li><li data-pid="FwlksRgP">（2）可以提示对方如何去准备同样格式的数据来训练模型。</li></ul><li data-pid="EI0YNjTW"><b>使用文档</b>：</li><ul><li data-pid="9dq2Ydir">（1）根据使用文档的步骤，每个人都可以重现模型；</li><li data-pid="ZARd-xUc">（2）包含了模型的使用细节和我们相关参数的设置依据等信息。</li></ul></ul><p data-pid="dBl1BBL1">可以看到，根据我们提供的<b>模型代码</b>/<b>模型参数</b>/<b>数据集</b>/<b>使用文档</b>，我们就可以有理由相信对方是有手就会了，那么目的就达到了。</p><p data-pid="t__Glisc"><b>现在我们反转一下思路，我们希望别人给我们提供模型的时候也能够提供这些信息，那么我们就可以拿捏住别人的模型了。</b></p><h2 id="h_620688513_1" data-into-catalog-status=""><b>为什么要约定格式？</b></h2><p data-pid="3ZstvSY2">根据上一段的思路，我们知道模型重现的关键是模型结构/模型参数/数据集，那么我们提供或者希望别人提供这些信息，需要一个交流的规范，这样才不会1000个人给出1000种格式，而<b> .pt .pth .bin 以及 .onnx 就是约定的格式</b>。</p><blockquote data-pid="RXpuRyaC"><a href="https://link.zhihu.com/?target=https%3A//pytorch.org/docs/stable/torch.html%3Fhighlight%3Dsave%23torch.save" class=" wrap external" target="_blank" rel="nofollow noreferrer" data-za-detail-view-id="1043">torch.save</a>: Saves a serialized object to disk. This function uses Python’s <a href="https://link.zhihu.com/?target=https%3A//docs.python.org/3/library/pickle.html" class=" wrap external" target="_blank" rel="nofollow noreferrer" data-za-detail-view-id="1043">pickle</a> utility for serialization. Models, tensors, and dictionaries of all kinds of objects can be saved using this function.</blockquote><p data-pid="NzR2Ykh6"><b>不同的后缀只是用于提示</b>我们文件可能包含的内容，但是具体的内容需要看模型提供者编写的<b>README.md</b>才知道。而在使用torch.load()方法加载模型信息的时候，并不是根据文件的后缀进行的读取，而是根据文件的实际内容自动识别的，<b>因此对于torch.load()方法而言，不管你把后缀改成是什么，只要文件是对的都可以读取</b>。</p><blockquote data-pid="5d9GQVG3"><a href="https://link.zhihu.com/?target=https%3A//pytorch.org/docs/stable/torch.html%3Fhighlight%3Dtorch%2520load%23torch.load" class=" wrap external" target="_blank" rel="nofollow noreferrer" data-za-detail-view-id="1043">torch.load</a>: Uses <a href="https://link.zhihu.com/?target=https%3A//docs.python.org/3/library/pickle.html" class=" wrap external" target="_blank" rel="nofollow noreferrer" data-za-detail-view-id="1043">pickle</a>’s unpickling facilities to deserialize pickled object files to memory. This function also facilitates the device to load the data into (see <a href="https://link.zhihu.com/?target=https%3A//pytorch.org/tutorials/beginner/saving_loading_models.html%3Fhighlight%3Dsaving%2520loading%23saving-loading-model-across-devices" class=" wrap external" target="_blank" rel="nofollow noreferrer" data-za-detail-view-id="1043">Saving &amp; Loading Model Across Devices</a>).</blockquote><p data-pid="eIxnxLxE">顺便提一下，“<b>一切皆文件”</b>的思维才是正确打开计算机世界的思维方式，文件后缀只作为提示作用，在Windows系统中也会用于提示系统默认如何打开或执行文件，除此之外，文件后缀不应该成为我们认识和了解文件阻碍。</p><h2 id="h_620688513_2" data-into-catalog-status="">格式汇总</h2><p data-pid="SopCGIg5">下面是一个整理了 <code>.pt</code>、<code>.pth</code>、<code>.bin</code>、ONNX 和 TorchScript 等 PyTorch 模型文件格式的表格：</p><table data-draft-node="block" data-draft-type="table" data-size="normal" data-row-style="normal"><tbody><tr><th>格式</th><th>解释</th><th>适用场景</th><th>可对应的后缀</th></tr><tr><td>.pt 或 .pth</td><td>PyTorch 的默认模型文件格式，用于保存和加载完整的 PyTorch 模型，包含模型的结构和参数等信息。</td><td>需要保存和加载完整的 PyTorch 模型的场景，例如在训练中保存最佳的模型或在部署中加载训练好的模型。</td><td>.pt 或 .pth</td></tr><tr><td>.bin</td><td>一种通用的二进制格式，可以用于保存和加载各种类型的模型和数据。</td><td>需要将 PyTorch 模型转换为通用的二进制格式的场景。</td><td>.bin</td></tr><tr><td>ONNX</td><td>一种通用的模型交换格式，可以用于将模型从一个深度学习框架转换到另一个深度学习框架或硬件平台。在 PyTorch 中，可以使用 torch.onnx.export 函数将 PyTorch 模型转换为 ONNX 格式。</td><td>需要将 PyTorch 模型转换为其他深度学习框架或硬件平台可用的格式的场景。</td><td>.onnx</td></tr><tr><td>TorchScript</td><td>PyTorch 提供的一种序列化和优化模型的方法，可以将 PyTorch 模型转换为一个序列化的程序，并使用 JIT 编译器对模型进行优化。在 PyTorch 中，可以使用 torch.jit.trace 或 torch.jit.script 函数将 PyTorch 模型转换为 TorchScript 格式。</td><td>需要将 PyTorch 模型序列化和优化，并在没有 Python 环境的情况下运行模型的场景。</td><td>.pt 或 .pth</td></tr></tbody></table><h2 id="h_620688513_3" data-into-catalog-status="">.pt .pth格式</h2><p data-pid="Fy2HCBKB">一个完整的Pytorch模型文件，包含了如下参数：</p><ul><li data-pid="iBIiphct">model_state_dict：模型参数</li><li data-pid="DzbejFjo">optimizer_state_dict：优化器的状态</li><li data-pid="S9WjM3c1">epoch：当前的训练轮数</li><li data-pid="yD5Pjyws">loss：当前的损失值</li></ul><p data-pid="-Y-SsE4g">下面是一个.pt文件的保存和加载示例（注意，后缀也可以是 .pth ）：</p><ul><li data-pid="LxRWrent">.state_dict()：包含所有的参数和持久化缓存的字典，model和optimizer都有这个方法</li><li data-pid="9pHtLHWn">torch.save()：将所有的组件保存到文件中</li></ul><p data-pid="V6Kbfa6O"><b>模型保存</b></p><div class="highlight"><pre><code class="language-python3"><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="c1"># 定义一个简单的模型</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>

<span class="c1"># 保存模型</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span>
            <span class="s1">'epoch'</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
            <span class="s1">'model_state_dict'</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'optimizer_state_dict'</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'loss'</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span>
            <span class="p">},</span> <span class="n">PATH</span><span class="p">)</span></code></pre></div><p data-pid="MLjd9pt_"><b>模型加载</b></p><div class="highlight"><pre><code class="language-text">import torch
import torch.nn as nn

# 定义同样的模型结构
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 5)
        self.fc2 = nn.Linear(5, 1)

    def forward(self, x):
        x = self.fc1(x)
        x = self.fc2(x)
        return x

# 加载模型
model = Net()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
checkpoint = torch.load(PATH)
model.load_state_dict(checkpoint['model_state_dict'])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']
loss = checkpoint['loss']
model.eval()</code></pre></div><h2 id="h_620688513_4" data-into-catalog-status="">.bin格式</h2><p data-pid="LgEOt9a7">.bin文件是一个二进制文件，可以保存Pytorch模型的参数和持久化缓存。.bin文件的大小较小，加载速度较快，因此在生产环境中使用较多。</p><p data-pid="y-Fd03hT">下面是一个.bin文件的保存和加载示例<b>（注意：也可以使用 .pt .pth 后缀）</b>：</p><p data-pid="6ac5_5kA"><b>保存模型</b></p><div class="highlight"><pre><code class="language-python3"><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="c1"># 定义一个简单的模型</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="c1"># 保存参数到.bin文件</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span></code></pre></div><p data-pid="S-HXkl_g"><b>加载模型</b></p><div class="highlight"><pre><code class="language-text">import torch
import torch.nn as nn

# 定义相同的模型结构
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 5)
        self.fc2 = nn.Linear(5, 1)

    def forward(self, x):
        x = self.fc1(x)
        x = self.fc2(x)
        return x

# 加载.bin文件
model = Net()
model.load_state_dict(torch.load(PATH))
model.eval()</code></pre></div><h2 id="h_620688513_5" data-into-catalog-status="">.onnx格式</h2><p data-pid="IgJ8HeDc">上述保存的文件可以通过PyTorch提供的<code>torch.onnx.export</code>函数<b>转化为ONNX格式</b>，这样可以在其他深度学习框架中使用PyTorch训练的模型。转化方法如下：</p><div class="highlight"><pre><code class="language-python3"><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.onnx</span>

<span class="c1"># 将模型保存为.bin文件</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s2">"model.bin"</span><span class="p">)</span>
<span class="c1"># torch.save(model.state_dict(), "model.pt")</span>
<span class="c1"># torch.save(model.state_dict(), "model.pth")</span>

<span class="c1"># 将.bin文件转化为ONNX格式</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"model.bin"</span><span class="p">))</span>
<span class="c1"># model.load_state_dict(torch.load("model.pt"))</span>
<span class="c1"># model.load_state_dict(torch.load("model.pth"))</span>
<span class="n">example_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">example_input</span><span class="p">,</span> <span class="s2">"model.onnx"</span><span class="p">,</span> <span class="n">input_names</span><span class="o">=</span><span class="p">[</span><span class="s2">"input"</span><span class="p">],</span> <span class="n">output_names</span><span class="o">=</span><span class="p">[</span><span class="s2">"output"</span><span class="p">])</span></code></pre></div><p data-pid="E8iibLZc"><b>加载ONNX格式</b>的代码可以参考以下示例代码：</p><div class="highlight"><pre><code class="language-python3"><span class="kn">import</span> <span class="nn">onnx</span>
<span class="kn">import</span> <span class="nn">onnxruntime</span>

<span class="c1"># 加载ONNX文件</span>
<span class="n">onnx_model</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"model.onnx"</span><span class="p">)</span>

<span class="c1"># 将ONNX文件转化为ORT格式</span>
<span class="n">ort_session</span> <span class="o">=</span> <span class="n">onnxruntime</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span><span class="s2">"model.onnx"</span><span class="p">)</span>

<span class="c1"># 输入数据</span>
<span class="n">input_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="c1"># 运行模型</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">ort_session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="s2">"input"</span><span class="p">:</span> <span class="n">input_data</span><span class="p">})</span>

<span class="c1"># 输出结果</span>
<span class="nb">print</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span></code></pre></div><p data-pid="4aylt7yp">注意，需要安装<code>onnx</code>和<code>onnxruntime</code>两个Python包。此外，还需要使用<code>numpy</code>等其他常用的科学计算库。</p><h2 id="h_620688513_6" data-into-catalog-status="">直接保存完整模型</h2><p data-pid="37gSN1k3">可以看出来，我们在之前的报错方式中，都是保存了.state_dict()，但是没有保存模型的结构，在其他地方使用的时候，必须先重新定义相同结构的模型（或兼容模型），才能够加载模型参数进行使用，如果我们想直接把整个模型都保存下来，避免重新定义模型，可以按如下操作：</p><div class="highlight"><pre><code class="language-text"># 保存模型
PATH = "entire_model.pt"
# PATH = "entire_model.pth"
# PATH = "entire_model.bin"
torch.save(model, PATH)</code></pre></div><p data-pid="7iqI14d9"><b>加载模型</b></p><div class="highlight"><pre><code class="language-text"># 加载模型
model = torch.load("entire_model.pt")
model.eval()</code></pre></div><h2 id="h_620688513_7" data-into-catalog-status="">结语</h2><p data-pid="HTrMd-iT">本文介绍了pytorch可以导出的模型的几种后缀格式，但是模型导出的关键并不是后缀，而是到处时候提供的信息到底是什么，只要知道了模型的model.state_dict()和optimizer.state_dict()，以及相应的epoch batch_size loss等信息，我们就能够重建出模型，至于要导出哪些信息，就取决于你了，务必在readme.md中写清楚，你导出了哪些信息。</p><table data-draft-node="block" data-draft-type="table" data-size="normal" data-row-style="normal"><tbody><tr><th>保存场景</th><th>保存方法</th><th>文件后缀</th></tr><tr><td>整个模型</td><td>model = Net()<br>torch.save(model, PATH)</td><td>.pt .pth .bin</td></tr><tr><td>仅模型参数</td><td>model = Net()<br>torch.save(model.state_dict(), PATH)</td><td>.pt .pth .bin</td></tr><tr><td>checkpoints使用</td><td>model = Net()<br>torch.save({<br>   'epoch': 10,<br>   'model_state_dict': model.state_dict(),<br>   'optimizer_state_dict': optimizer.state_dict(),<br>   'loss': loss,<br>}, PATH)</td><td>.pt .pth .bin</td></tr><tr><td>ONNX通用保存</td><td>model = Net()<br>model.load_state_dict(torch.load("model.bin"))<br>example_input = torch.randn(1, 3)<br>torch.onnx.export(model, example_input, "model.onnx", input_names=["input"], output_names=["output"])</td><td>.onnx</td></tr><tr><td>TorchScript无python环境使用</td><td>model = Net()<br>model_scripted = torch.jit.script(model) # Export to TorchScript<br>model_scripted.save('model_scripted.pt')<br><br><br>使用时：<br>model = torch.jit.load('model_scripted.pt')<br>model.eval()</td><td>.pt .pth</td></tr></tbody></table><h2 id="h_620688513_8" data-into-catalog-status=""><b>参考资料</b></h2><ol><li data-pid="jGbMbxcv"><a href="https://link.zhihu.com/?target=https%3A//pytorch.org/tutorials/beginner/saving_loading_models.html%3Fhighlight%3Dsaving%2520loading" class=" wrap external" target="_blank" rel="nofollow noreferrer">Saving and Loading Models</a></li><li data-pid="O9PqSPXu"><a href="https://link.zhihu.com/?target=https%3A//pytorch.org/tutorials/recipes/recipes/saving_and_loading_models_for_inference.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">Saving and loading models for inference in PyTorch</a></li><li data-pid="9OohvEg-"><a href="https://link.zhihu.com/?target=https%3A//pytorch.org/tutorials/recipes/recipes/saving_multiple_models_in_one_file.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">Saving and loading multiple models in one file using PyTorch</a></li><li data-pid="YGpKUUG_"><a href="https://link.zhihu.com/?target=https%3A//pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">Saving and loading a general checkpoint in PyTorch</a></li><li data-pid="kJFQa1gR"><a href="https://link.zhihu.com/?target=https%3A//pytorch.org/tutorials/recipes/recipes/save_load_across_devices.html%3Fhighlight%3Dsaving%2520loading" class=" wrap external" target="_blank" rel="nofollow noreferrer">Saving and loading models across devices in PyTorch</a></li><li data-pid="RmTRy-pB"><a href="https://link.zhihu.com/?target=https%3A//pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html%3Fhighlight%3Donnx" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">pytorch.org/tutorials/a</span><span class="invisible">dvanced/super_resolution_with_onnxruntime.html?highlight=onnx</span><span class="ellipsis"></span></a></li></ol><p data-pid="YZxW7Y7B">By the way，以上均为官方文档资料，写得非常的清晰易懂，如果想仔细学习模型的导出和加载方法，强烈推荐学习上述文档，文档内容条理清晰、易读易用。</p></div></div></div></div><div role="button" tabindex="0" class="ContentItem-time">编辑于 2023-04-15 16:54<!-- -->・IP 属地美国</div><div class="Post-topicsAndReviewer"><div class="TopicList Post-Topics"><div class="Tag Topic css-1s3a4zw" data-za-detail-view-path-module="TopicItem" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Topic&quot;,&quot;token&quot;:&quot;20075993&quot;}}}"><span class="Tag-content"><a class="TopicLink" href="//www.zhihu.com/topic/20075993" target="_blank"><div class="css-1gomreu">PyTorch</div></a></span></div><div class="Tag Topic css-1s3a4zw" data-za-detail-view-path-module="TopicItem" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Topic&quot;,&quot;token&quot;:&quot;19579715&quot;}}}"><span class="Tag-content"><a class="TopicLink" href="//www.zhihu.com/topic/19579715" target="_blank"><div class="css-1gomreu">模型</div></a></span></div></div></div><div><div class="Sticky RichContent-actions is-fixed is-bottom" style="width: 690px; bottom: 0px; left: 155px;"><div class="ContentItem-actions" data-za-detail-view-path-module="BottomBar" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Post&quot;,&quot;id&quot;:&quot;620688513&quot;}}}"><span><button aria-label="赞同 137 " aria-live="polite" type="button" class="Button VoteButton VoteButton--up"><span style="display:inline-flex;align-items:center">&ZeroWidthSpace;<svg width="10" height="10" viewBox="0 0 24 24" class="Zi Zi--TriangleUp VoteButton-TriangleUp" fill="currentColor"><path fill-rule="evenodd" d="M13.792 3.681c-.781-1.406-2.803-1.406-3.584 0l-7.79 14.023c-.76 1.367.228 3.046 1.791 3.046h15.582c1.563 0 2.55-1.68 1.791-3.046l-7.79-14.023Z" clip-rule="evenodd"></path></svg></span>赞同 137</button><button aria-label="反对" aria-live="polite" type="button" class="Button VoteButton VoteButton--down"><span style="display:inline-flex;align-items:center">&ZeroWidthSpace;<svg width="10" height="10" viewBox="0 0 24 24" class="Zi Zi--TriangleDown" fill="currentColor"><path fill-rule="evenodd" d="M13.792 20.319c-.781 1.406-2.803 1.406-3.584 0L2.418 6.296c-.76-1.367.228-3.046 1.791-3.046h15.582c1.563 0 2.55 1.68 1.791 3.046l-7.79 14.023Z" clip-rule="evenodd"></path></svg></span></button></span><button type="button" class="Button BottomActions-CommentBtn Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">&ZeroWidthSpace;<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Comment Button-zi" fill="currentColor"><path fill-rule="evenodd" d="M12 2.75a9.25 9.25 0 1 0 4.737 17.197l2.643.817a1 1 0 0 0 1.25-1.25l-.8-2.588A9.25 9.25 0 0 0 12 2.75Z" clip-rule="evenodd"></path></svg></span>11 条评论</button><div class="Popover ShareMenu"><div class="ShareMenu-toggler" id="Popover2-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover2-content"><button type="button" class="Button Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">&ZeroWidthSpace;<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Share Button-zi" fill="currentColor"><path d="M19.47 1.914a.8.8 0 0 1 1.204.778l-1.872 16.386a.9.9 0 0 1-1.204.743l-4.615-1.692a.7.7 0 0 0-.831.28l-1.927 3.02c-.43.674-1.474.369-1.474-.43v-3.865a.8.8 0 0 1 .179-.504l5.808-7.148a.595.595 0 0 0-.897-.781l-5.93 6.354a1.1 1.1 0 0 1-1.258.252L2.57 13.46a.8.8 0 0 1-.08-1.415l16.98-10.13Z"></path></svg></span>分享</button></div></div><button aria-live="polite" type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">&ZeroWidthSpace;<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Heart Button-zi" fill="currentColor"><path fill-rule="evenodd" d="M12.004 4.934c1.015-.944 2.484-1.618 3.98-1.618 3.48 0 6.53 3.265 6.15 7.614-.11 1.254-.686 2.55-1.458 3.753-.778 1.215-1.79 2.392-2.845 3.419-1.054 1.028-2.168 1.923-3.161 2.566a9.96 9.96 0 0 1-1.41.777c-.418.182-.862.32-1.268.32s-.848-.137-1.267-.317a9.918 9.918 0 0 1-1.407-.771c-.992-.64-2.103-1.53-3.156-2.555-1.052-1.024-2.062-2.2-2.84-3.417-.77-1.208-1.346-2.51-1.456-3.775-.38-4.349 2.67-7.614 6.15-7.614 1.484 0 2.983.673 3.988 1.618Z" clip-rule="evenodd"></path></svg></span>喜欢</button><button type="button" class="Button Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">&ZeroWidthSpace;<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Star Button-zi" fill="currentColor"><path d="M10.484 3.307c.673-1.168 2.358-1.168 3.032 0l2.377 4.122a.25.25 0 0 0 .165.12l4.655.987c1.319.28 1.84 1.882.937 2.884l-3.186 3.535a.25.25 0 0 0-.063.193l.5 4.733c.142 1.34-1.222 2.33-2.453 1.782l-4.346-1.938a.25.25 0 0 0-.204 0l-4.346 1.938c-1.231.549-2.595-.442-2.453-1.782l.5-4.733a.25.25 0 0 0-.064-.193L2.35 11.42c-.903-1.002-.382-2.604.937-2.884l4.655-.987a.25.25 0 0 0 .164-.12l2.378-4.122Z"></path></svg></span>收藏</button><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">&ZeroWidthSpace;<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Deliver Button-zi" fill="currentColor"><g fill-rule="evenodd" clip-rule="evenodd"><path d="M7.821 12a.75.75 0 0 1 .75-.75h6.857a.75.75 0 0 1 0 1.5H8.571a.75.75 0 0 1-.75-.75ZM8.965 8a.75.75 0 0 1 .75-.75h4.571a.75.75 0 0 1 0 1.5H9.715a.75.75 0 0 1-.75-.75Z"></path><path d="M7.527 3.15a2.35 2.35 0 0 0-2.309 1.91L3.165 15.84a.85.85 0 0 0-.015.16v2.5a2.35 2.35 0 0 0 2.35 2.35h13a2.35 2.35 0 0 0 2.35-2.35V16a.848.848 0 0 0-.015-.16L18.78 5.06a2.35 2.35 0 0 0-2.308-1.91H7.527Zm0 1.7a.65.65 0 0 0-.639.528l-1.88 9.872h13.984l-1.88-9.872a.65.65 0 0 0-.64-.528H7.528Z"></path></g></svg></span>申请转载</button><div class="Post-ActionMenuButton"><div class="Popover"><div id="Popover3-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover3-content"><button type="button" class="Button Button--plain Button--withIcon Button--iconOnly undefined"><span style="display:inline-flex;align-items:center">&ZeroWidthSpace;<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" class="Zi Zi--Dots Button-zi" fill="currentColor"><path d="M5.165 13.665a1.665 1.665 0 1 0 0-3.33 1.665 1.665 0 0 0 0 3.33ZM13.665 12a1.665 1.665 0 1 1-3.33 0 1.665 1.665 0 0 1 3.33 0ZM18.835 13.665a1.665 1.665 0 1 0 0-3.33 1.665 1.665 0 0 0 0 3.33Z"></path></svg></span></button></div></div></div></div><div class="Post-SideActions" style="opacity: 1;"><button class="like"><div class="Post-SideActions-icon"><svg width="16" height="16" viewBox="0 0 24 24" class="Zi Zi--TriangleUp Post-SideActions-upIcon" fill="currentColor"><path fill-rule="evenodd" d="M13.792 3.681c-.781-1.406-2.803-1.406-3.584 0l-7.79 14.023c-.76 1.367.228 3.046 1.791 3.046h15.582c1.563 0 2.55-1.68 1.791-3.046l-7.79-14.023Z" clip-rule="evenodd"></path></svg></div><div class="likeCount"><div class="likeCount-inner" data-previous="已赞同 138">赞同 137</div></div></button><div class="Popover ShareMenu"><div class="ShareMenu-toggler" id="Popover10-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover10-content"><button><div class="Post-SideActions-icon"><span style="display: inline-flex; align-items: center;">&ZeroWidthSpace;<svg width="20" height="20" viewBox="0 0 24 24" class="Zi Zi--Share" fill="currentColor"><path d="M19.47 1.914a.8.8 0 0 1 1.204.778l-1.872 16.386a.9.9 0 0 1-1.204.743l-4.615-1.692a.7.7 0 0 0-.831.28l-1.927 3.02c-.43.674-1.474.369-1.474-.43v-3.865a.8.8 0 0 1 .179-.504l5.808-7.148a.595.595 0 0 0-.897-.781l-5.93 6.354a1.1 1.1 0 0 1-1.258.252L2.57 13.46a.8.8 0 0 1-.08-1.415l16.98-10.13Z"></path></svg></span></div>分享</button></div></div></div></div><div class="Sticky--holder" style="position: static; inset: auto auto 0px 0px; display: block; float: none; margin: 0px 0px 10px; height: 53.28px;"></div></div></article>